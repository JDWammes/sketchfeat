{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn import linear_model, datasets, neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use vgg19 to extract sketch features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deactivate(net):\n",
    "    net.eval()\n",
    "    for p in net.parameters():\n",
    "        p.requires_grad = False  \n",
    "        \n",
    "use_cuda = torch.cuda.is_available()\n",
    "cuda_device = 3\n",
    "\n",
    "vgg19 = models.vgg19(pretrained=True).cuda(cuda_device)\n",
    "vgg19_features = deepcopy(vgg19.features)\n",
    "vgg19_classifier = deepcopy(vgg19.classifier)\n",
    "\n",
    "# remove last layer of classifier\n",
    "vgg19_classifier = nn.Sequential(*(list(vgg19_classifier.children())[:-1]))\n",
    "\n",
    "if use_cuda:\n",
    "    vgg19_features.cuda(cuda_device)\n",
    "    vgg19_classifier.cuda(cuda_device)\n",
    "\n",
    "deactivate(vgg19_features)\n",
    "deactivate(vgg19_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get sketch data and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sketches: 1380\n",
      "Number of subjects: 35\n"
     ]
    }
   ],
   "source": [
    "def list_files(path, ext='png'):\n",
    "    result = [y for x in os.walk(path)\n",
    "              for y in glob(os.path.join(x[0], '*.%s' % ext))]\n",
    "    return result\n",
    "\n",
    "def get_label_from_path(path):\n",
    "    return path.split('.')[-2].split('_')[-1]    \n",
    "\n",
    "def get_trial_from_path(path):\n",
    "    return path.split('_')[-2]\n",
    "\n",
    "def get_subj_from_path(path):\n",
    "    return path.split('/')[1]\n",
    "\n",
    "# extract metadata\n",
    "path_to_sketches = 'sketches'\n",
    "sketch_paths = list_files(path_to_sketches)\n",
    "labels = map(get_label_from_path,sketch_paths)\n",
    "trialNum = map(get_trial_from_path,sketch_paths)\n",
    "subj = map(get_subj_from_path,sketch_paths)\n",
    "\n",
    "# organize into dataframe\n",
    "X = pd.DataFrame([subj,trialNum,labels,sketch_paths])\n",
    "X = X.transpose()\n",
    "X.columns = ['subj','trial','label','path']\n",
    "\n",
    "print 'Number of sketches: ' + str(len(sketch_paths))\n",
    "print 'Number of subjects: ' + str(len(np.unique(subj)))\n",
    "\n",
    "num_sketches = len(sketch_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Batch 2\n",
      "Batch 3\n",
      "Batch 4\n",
      "Batch 5\n",
      "Batch 6\n",
      "Batch 7\n",
      "Batch 8\n",
      "Batch 9\n",
      "Batch 10\n",
      "Batch 11\n",
      "Batch 12\n",
      "Batch 13\n",
      "Batch 14\n",
      "Batch 15\n",
      "Batch 16\n",
      "Batch 17\n",
      "Batch 18\n",
      "Batch 19\n",
      "Batch 20\n",
      "Batch 21\n",
      "Batch 22\n",
      "stopped!\n"
     ]
    }
   ],
   "source": [
    "def load_image(path, imsize=224, volatile=True, use_cuda=False):\n",
    "    im = Image.open(path)\n",
    "    im = im.convert('RGB')\n",
    "\n",
    "    loader = transforms.Compose([\n",
    "        transforms.Scale(imsize),\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "    im = Variable(loader(im), volatile=volatile)\n",
    "    im = im.unsqueeze(0)\n",
    "    if use_cuda:\n",
    "        im = im.cuda(cuda_device)\n",
    "    return im\n",
    "\n",
    "def sketch_generator(paths, imsize=224, use_cuda=use_cuda):\n",
    "    for path in paths:\n",
    "        sketch = load_image(path)\n",
    "        label = get_label_from_path(path)\n",
    "        yield (sketch, label)\n",
    "\n",
    "# define generator\n",
    "generator = sketch_generator(sketch_paths,imsize=224,use_cuda=use_cuda)\n",
    "\n",
    "# initialize sketch and label matrices\n",
    "Features = []\n",
    "Labels = []\n",
    "n = 0\n",
    "quit = False \n",
    "\n",
    "# generate batches of sketches and labels    \n",
    "if generator:\n",
    "    while True:    \n",
    "        batch_size = 64\n",
    "        sketch_batch = Variable(torch.zeros(batch_size, 3, 224, 224))\n",
    "        if use_cuda:\n",
    "            sketch_batch = sketch_batch.cuda(cuda_device)                \n",
    "        label_batch = []   \n",
    "        print('Batch {}'.format(n + 1))            \n",
    "        for b in range(batch_size):\n",
    "            try:\n",
    "                sketch, label = generator.next()\n",
    "                sketch_batch[b] = sketch   \n",
    "                label_batch.append(label)\n",
    "            except StopIteration:\n",
    "                quit = True\n",
    "                print 'stopped!'\n",
    "                break                \n",
    "            \n",
    "        if n == num_sketches//batch_size:\n",
    "            sketch_batch = sketch_batch.narrow(0,0,b)\n",
    "            label_batch = label_batch[:b + 1] \n",
    "        n = n + 1       \n",
    "\n",
    "        # extract features from batch\n",
    "        sketch_batch = vgg19_features(sketch_batch) \n",
    "        sketch_batch = sketch_batch.view(sketch_batch.size(0), -1)\n",
    "        sketch_batch = vgg19_classifier(sketch_batch)\n",
    "        sketch_batch = sketch_batch.cpu().data.numpy()\n",
    "\n",
    "        if len(Features)==0:\n",
    "            Features = sketch_batch\n",
    "        else:\n",
    "            Features = np.vstack((Features,sketch_batch))\n",
    "        Labels.append(label_batch)\n",
    "\n",
    "        if n == num_sketches//batch_size + 1:\n",
    "            break\n",
    "Labels = [item for sublist in Labels for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(np.corrcoef(Features))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
