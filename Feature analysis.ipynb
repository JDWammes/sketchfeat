{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Set up\n",
    "\n",
    "## dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "import pickle\n",
    "import scipy\n",
    "from sklearn import linear_model, datasets, neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# I pulled activations of 8 layers. Here is the index ref to the layers\n",
    "LAYERS = {'pool1': 0, 'pool2': 1, 'pool3': 2, 'pool4': 3,\n",
    "          'pool5': 4, 'fc6': 5, 'fc7': 6, 'prob': 7}\n",
    "\n",
    "# constants for the images\n",
    "NUM_VIEWS = 40\n",
    "CARS = ['limo', 'suv', 'smart', 'sedan']\n",
    "FURNITURES = ['bed', 'chair', 'table', 'bench']\n",
    "OBJECTS = CARS + FURNITURES\n",
    "# sample image url: https://s3.amazonaws.com/morphrecog-images-1/limoToSUV_10_10_99.png.png\n",
    "# CARS_label = ['limoToSUV_10','limoToSUV_99','smartToSedan_10','smartToSedan_99'];\n",
    "# FIURNITURES_label = ['bedChair_1', 'bedChair_100', 'tableBench_1', 'tableBench_100']\n",
    "\n",
    " \n",
    "\n",
    "# constants for train/test for the linear discriminability\n",
    "TRAIN_SZ = 0.80\n",
    "TEST_SZ = 1 - TRAIN_SZ\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pulling and cleaning up the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# downloading the activations. I had to split the sample (each act has 160 images) because they're about 3GB each. \n",
    "act1 = pickle.load(open('activations.p', 'rb'))\n",
    "act2 = pickle.load(open('activations2.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pulling out all the fc6, fc7 layers for all images to have a smaller set to work with. \n",
    "fc6 = np.vstack((np.asarray(act1[LAYERS['fc6']]), np.asarray(act2[LAYERS['fc6']])))\n",
    "fc7 = np.vstack((np.asarray(act1[LAYERS['fc7']]), np.asarray(act2[LAYERS['fc7']])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling out remaining pooling layers\n",
    "pool = [] \n",
    "\n",
    "for i in xrange(0,5):\n",
    "    pool1_i, pool2_i = np.asarray(act1[i]), np.asarray(act2[i])\n",
    "\n",
    "    pool_i = np.vstack((pool1_i.reshape(pool1_i.shape[0], pool1_i.shape[1] * pool1_i.shape[2] * pool1_i.shape[3]), \n",
    "                     pool2_i.reshape(pool2_i.shape[0], pool2_i.shape[1] * pool2_i.shape[2] * pool2_i.shape[3])))\n",
    "    pool.append(pool_i)\n",
    "\n",
    "# checking that i'm pulling the arrays correctly.... \n",
    "# using pool5 because it's the smallest. \n",
    "# pool[4][20][10:50]\n",
    "# foo = act1[4][20].flatten()\n",
    "# foo[10:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Representational Similarity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# getMeanVector gets the mean vector across number of views for num_objects \n",
    "def getMeanVector(full_batch, num_views, num_objects):\n",
    "    meanVector = np.empty((num_objects, full_batch.shape[1]), float)\n",
    "    for i in xrange(0, num_objects):\n",
    "        # pull out the views of the particular object \n",
    "        all_views = full_batch[i * num_views: (i + 1) * num_views, :]\n",
    "        meanVector[i] = np.mean(all_views, axis = 0)\n",
    "\n",
    "    \n",
    "    return meanVector\n",
    "# might need to normalize when takigng mean vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDM_fc7 = np.corrcoef(getMeanVector(fc7, NUM_VIEWS, len(OBJECTS))) \n",
    "imgplot = plt.imshow(RDM_fc7)\n",
    "#plt.axis(['limo', 'SUV', 'smart car', 'sedan', 'bed', 'chair', 'bench', 'bed'])\n",
    "# plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$')\n",
    "plt.colorbar();\n",
    "print CARS + FURNITURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDM_fc6 = np.corrcoef(getMeanVector(fc6, NUM_VIEWS, len(OBJECTS))) \n",
    "imgplot = plt.imshow(RDM_fc6)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"If the fc6 and fc7 RDM look similar, they are-- note:\"\n",
    "print \"Taking the difference between fc6 and fc7, we have: \"  + str((fc6 - fc7).max())\n",
    "print \"Taking the difference between RDM of fc6 and fc7, we have: \" + str((RDM_fc6 - RDM_fc7).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Linear Discriminability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# full_batch: the full batch of images. I am assuming that the full_batch is arranged as 40 views of obj1, 40 objects of obj2... so forth.  \n",
    "# train_sz: needs to be a probability, s.t. test_sz = 1 - train-sz. \n",
    "def getData(full_batch, num_views, num_objects, test_sz):\n",
    "    \n",
    "    num_train = int(num_views * (1 - test_sz))\n",
    "    num_test = num_views - num_train\n",
    "    \n",
    "    X_train = np.ones((num_train * num_objects, full_batch.shape[1]), float)\n",
    "    X_test = np.ones((num_test * num_objects, full_batch.shape[1]), float)\n",
    "    \n",
    "    for i in xrange(0, num_objects):\n",
    "        X = full_batch[i * num_views: (i + 1) * num_views, :]\n",
    "        \n",
    "        # randomly shuffle the train/test for the x \n",
    "        X_train_i, X_test_i = train_test_split(X, test_size=test_sz)\n",
    "        X_train[i * num_train: (i + 1) * num_train, :] = X_train_i\n",
    "        X_test[i * num_test: (i + 1) * num_test, :] = X_test_i\n",
    "        \n",
    "        \n",
    "\n",
    "    y_train = np.repeat(xrange(0, num_objects), num_train)\n",
    "    y_test = np.repeat(xrange(0, num_objects), num_test)\n",
    "\n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "# mini-test for the fnc \n",
    "# X_train, y_train, X_test, y_test = getData(fc6, NUM_VIEWS, len(OBJECTS), TEST_SZ)\n",
    "# print \"here is the full thing\" \n",
    "# print np.sort(fc6[0:40,1])\n",
    "# print \"X_train\"\n",
    "# print np.sort(X_train[0:32,1])\n",
    "# print \"X_test\"\n",
    "# print np.sort(X_test[0:8, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = linear_model.LogisticRegression()\n",
    "X_train, y_train, X_test, y_test = getData(fc6, NUM_VIEWS, len(OBJECTS), TEST_SZ)\n",
    "# for sanity check: X_test_r = np.random.rand(X_test.shape[0], X_test.shape[1])\n",
    "print('LogisticRegression score: %f'\n",
    "      % logreg.fit(X_test, y_test).score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = linear_model.LogisticRegression()\n",
    "X_train, y_train, X_test, y_test = getData(fc7, NUM_VIEWS, len(OBJECTS), TEST_SZ)\n",
    "# for sanity check: X_test_r = np.random.rand(X_test.shape[0], X_test.shape[1])\n",
    "print('LogisticRegression score: %f'\n",
    "      % logreg.fit(X_test, y_test).score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
